FROM jupyter/scipy-notebook:python-3.10

USER root

# Install Java 17 (required for Spark 3.5)
RUN apt-get update && \
    apt-get install -y openjdk-17-jdk && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME - detect architecture
RUN if [ "$(uname -m)" = "aarch64" ] || [ "$(uname -m)" = "arm64" ]; then \
        echo "export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64" >> /etc/profile.d/java.sh; \
    else \
        echo "export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64" >> /etc/profile.d/java.sh; \
    fi

# Set JAVA_HOME based on actual installed JDK path
RUN JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java)))) && \
    echo "export JAVA_HOME=${JAVA_HOME}" > /etc/environment

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$PATH:$JAVA_HOME/bin
ENV PYTHONPATH=/home/jovyan/work:$PYTHONPATH

USER $NB_USER

# Install PySpark 3.5.7 (must match Spark cluster version)
RUN pip install --quiet \
    pyspark==3.5.7 \
    pyarrow \
    fsspec \
    && fix-permissions "${CONDA_DIR}" \
    && fix-permissions "/home/${NB_USER}"

